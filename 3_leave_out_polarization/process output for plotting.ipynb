{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "TWEET_DIR = '../data/tweets/'\n",
    "NUM_CLUSTERS = 6\n",
    "events = open(DATA_DIR + 'event_names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filter_method = '_noRT' # make sure to include underscore\n",
    "cluster_method = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_dict = json.load(open(DATA_DIR + \"event_year.json\",\"r\"))\n",
    "shooter_race = json.load(open(DATA_DIR + \"shooters_race.json\",\"r\"))\n",
    "polarization_dict = json.load(open(DATA_DIR + \"polarization\"+data_filter_method+\".json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "between_topic_pol = json.load(open(DATA_DIR + \"between_topic_polarization\"+cluster_method+\".json\",\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting overall polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "y_random = []\n",
    "labels=[]\n",
    "ex = ['fort_lauderdale']  # we exclude Fort Lauderdale because we only have data for the first day after the shooting\n",
    "for e, t in time_dict.items():\n",
    "    if e in ex:\n",
    "        continue\n",
    "    label = e.split('_')\n",
    "    new_label = []\n",
    "    for l in label:\n",
    "        new_label.append(l[0].upper() + l[1:])\n",
    "    new_label = ' '.join(new_label)\n",
    "    \n",
    "    x_val = float(2000+t)\n",
    "    y_val = float(polarization_dict[e][0])\n",
    "    y_random_val = float(float(polarization_dict[e][1]))\n",
    "    x.append(x_val)\n",
    "    y.append(y_val)\n",
    "    y_random.append(y_random_val)\n",
    "    labels.append(new_label)\n",
    "    #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y + y_random), 'label':labels * 2, 'is_actual':['actual value']* len(y) + ['value resulting from random party assignment']* len(y)})\n",
    "df.to_csv(DATA_DIR + \"polarization\"+data_filter_method+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting within vs between topic polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annapolis 18442\n",
      "baton_rouge 28960\n",
      "burlington 4980\n",
      "chattanooga 20697\n",
      "colorado_springs 39683\n",
      "dallas 143866\n",
      "fresno 6119\n",
      "kalamazoo 6785\n",
      "nashville 24312\n",
      "orlando 534700\n",
      "parkland 186329\n",
      "pittsburgh 36879\n",
      "roseburg 11488\n",
      "san_bernardino 44760\n",
      "san_francisco 6623\n",
      "santa_fe 42934\n",
      "sutherland_springs 106112\n",
      "thornton 9157\n",
      "thousand_oaks 62700\n",
      "vegas 725505\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y_between = []\n",
    "y_within = []\n",
    "labels=[]\n",
    "race = []\n",
    "ex = ['fort_lauderdale']\n",
    "for e, t in time_dict.items():\n",
    "    if e in ex:\n",
    "        continue\n",
    "    label = e.split('_')\n",
    "    new_label = []\n",
    "    for l in label:\n",
    "        new_label.append(l[0].upper() + l[1:])\n",
    "    new_label = ' '.join(new_label)\n",
    "    \n",
    "    within_topic_pol = json.load(open(TWEET_DIR +e+\"/\"+e+\"_topic_polarization\"+cluster_method+\".json\",\"r\"))\n",
    "    \n",
    "    # get the topic proportions\n",
    "    topics = np.load(TWEET_DIR + e + '/' + e + '_cluster_labels_' + str(NUM_CLUSTERS) + cluster_method + '.npy')\n",
    "    print(e, len(topics))\n",
    "    within_topic_pol_val = (np.array([float(within_topic_pol[str(i)][0]) for i in range(NUM_CLUSTERS)]) * np.bincount(topics)).sum() / len(topics)\n",
    "    \n",
    "    x_val = float(2000+t)\n",
    "    y_between_val = float(between_topic_pol[e][0])\n",
    "    y_within_val = within_topic_pol_val\n",
    "    x.append(x_val)\n",
    "    y_between.append(y_between_val)\n",
    "    y_within.append(y_within_val)\n",
    "    labels.append(new_label)\n",
    "    race.append(shooter_race[e])\n",
    "    #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y_between + y_within), 'label':labels * 2, 'kind':['between-topic']* len(y_between) + ['within-topic']* len(y_within), 'race':race * 2})\n",
    "df.to_csv(DATA_DIR + \"topic_polarization\"+cluster_method+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
